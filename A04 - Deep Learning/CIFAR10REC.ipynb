{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31def4b9",
   "metadata": {},
   "source": [
    "# 4 CIFAR10REC\n",
    "__Cifar10 Visual Recognition Challenge__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2602c511",
   "metadata": {},
   "source": [
    "In this notebook, you will again deal with [PyTorch](https://pytorch.org/), a popular deep learning framework for scientific research. Most of the code is already written, including a deep neural network model.\n",
    "However, the performance of said model is subpar. It is your task to complete the indicated functions and cells, so that you can train the model. Further, you should change and tweak the model as well as hyperparameters to create a well performing model. You can aim for accuracies in the 50ies!\n",
    "\n",
    "Experiment around with architecture choices and different hyperparamters. The lecture slides and PyTorch documentation give you a good overview of what is possible. Keep in mind, though, that blindly copy-pasting code from other sources without proper referencing and consent is plagiarism!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65564fec",
   "metadata": {},
   "source": [
    "The quality of your model is evaluated on the test dataset. Continously optimizing your model according to the performance on the test data set is bad scientific practice. Ideally, the evaluation on the test data should happen  just once, when you are confident that you have trained your model to the best of your knowledge. While tweaking your model, you may evaluate its quality on a validation set of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95185b53",
   "metadata": {},
   "source": [
    "You are not allowed to change arbitrary code of the notebook. Instead, functions, variables etc. which you can change, will be indicated explicitely (see __Task__ keyword).\n",
    "Please leave the seeds intact!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883298bb",
   "metadata": {},
   "source": [
    "## 4.1 Installing PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b450bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "torch.manual_seed(42)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8516e4",
   "metadata": {},
   "source": [
    "## 4.2 Obtaining the Dataset\n",
    "We are going to use the [Cifar10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset, which is a more difficult alternative to well-known [MNIST](http://yann.lecun.com/exdb/mnist/) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c3e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if, for some reason, you are not using a UNIX-based operating system, \\\n",
    "# you might need to adjust the path arguments\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=torchvision.transforms.ToTensor())\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "label_names = {0:'airplane', 1: 'automobile',2: 'bird',3: 'cat',4: 'deer',5: 'dog',6: 'frog',7: \n",
    "               'horse',8: 'ship',9: 'truck'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ffddfb",
   "metadata": {},
   "source": [
    "### Task 4.2.1 Inspecting a Sample from the Data\n",
    "Choose a random sample from the training data, and:\n",
    "- print its shape\n",
    "- visualize the sample with an appropriate plot\n",
    "- print its label (or title the plot appropriately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dabce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddcb811",
   "metadata": {},
   "source": [
    "### Task 4.2.2 Validation Split \n",
    "\n",
    "__YOU MAY EDIT PARTS OF THE NEXT CELL__\n",
    "\n",
    "In order to judge the quality of your training efforts, you might want to validate your model on a part of the data it has not seen yet. However, we cannot do that repeatedly on the test dataset.\n",
    "\n",
    "Therefore, we can split off some data from our training data. Make a decision about the validation split! The more data you take off from the training set, the more accurate will your evaluation be. The less data you leave for actual training, the worse your model performance will be.\n",
    "\n",
    "_Hint: Currently, the validation size is 100, which seems a bit small._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3dd51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 100 # set the size of your validation set\n",
    "trainset, valset = torch.utils.data.random_split(trainset, \n",
    "                                                 [len(trainset)-validation_size, validation_size], \n",
    "                                                 generator=torch.Generator().manual_seed(1337))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b6abf",
   "metadata": {},
   "source": [
    "### 4.2.3 Torch DataLoader\n",
    "Now we can hand over our three datasets to the DataLoader class which brings a lot of convience to the training procedure. It can batch and shuffle our data.\n",
    "\n",
    "The batch size is set to 32 which is an appropriate value. You may change the batch_size for the trainloader, if you want.\n",
    "\n",
    "Shuffling is not needed for validation and testing because we are only running through the data once, anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=32,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f344cd",
   "metadata": {},
   "source": [
    "## Task 4.3 Building a Model\n",
    "__YOU MAY EDIT PARTS OF THE NEXT CELL__\n",
    "\n",
    "We are going to use [torch.nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) to build a multi-layer perceptron (not a CNN!).\n",
    "You can simply supply [layers and building blocks](https://pytorch.org/docs/stable/nn.html) as arguments to create your network architecture in a sequential way, i.e. the data will flow through the network in the order they are listed as arguments.\n",
    "\n",
    "Useful modules for MLPs are:\n",
    "- [Linear Layers](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
    "- [Activation Functions](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
    "- [Dropout Layers](https://pytorch.org/docs/stable/nn.html#dropout-layers)\n",
    "- [Batch Normalization](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html?highlight=batchnormalization)\n",
    "\n",
    "The input to the model is an image, which has to be flattened to a vector, so that it is represented as suitable input for the MLP.\n",
    "\n",
    "The output must be a vector of size 10 (according to our labels/classes).\n",
    "\n",
    "You are supplied with a model that does not perform too well. You are free to build a MLP of your choice. Be aware that larger networks will take more time to train!\n",
    "\n",
    "Tips for experimentation:\n",
    "- Layer sizes\n",
    "- Number of layers\n",
    "- Activation functions\n",
    "- Dropout\n",
    "- Batch Normalization\n",
    "\n",
    "_Hint: What is known in PyTorch as a linear layer refers to a fully connected or dense layer._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e276ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "                      nn.Flatten(),\n",
    "                      nn.Linear(32*32*3, 512),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(512, 10),\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae5bd7",
   "metadata": {},
   "source": [
    "## 4.4 Training the Model\n",
    "Now that we have a model architecture, we will need to specify a training procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424e72e1",
   "metadata": {},
   "source": [
    "### Task 4.4.1 Choosing Hyperparameters\n",
    "__YOU MAY EDIT PARTS OF THE NEXT CELL__\n",
    "\n",
    "A few parameters for the training process need to be predefined and are not learned via gradient descent or backprop. We refere to these as hyperparameters.\n",
    "\n",
    "In the following, you are presented with four of those that shape the training process and can have great influence on the trained models performance.\n",
    "\n",
    "The machine-learning practictioner who set up this notebook apparently did not pay full attention to the lecture and literature. Although all lead to a working model, the values of some are not chosen to the best of our knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435bbf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88211e31",
   "metadata": {},
   "source": [
    "### 4.4.2 The Training Function\n",
    "The function `train` trains your model for one epoch and keeps track of the correct/incorrect predictions. It takes a model, a dataloader, and optimizer and a loss function, trains the model for one epoch and returns the mean loss over the epoch as well as the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10439af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for img, lbl in dataloader:\n",
    "        optimizer.zero_grad() \n",
    "        out = model(img) \n",
    "        logits, indices = torch.max(out, 1)\n",
    "        correct += torch.sum(indices == lbl).item()\n",
    "        total += len(lbl)\n",
    "        batch_loss = loss(out, lbl) \n",
    "        batch_loss.backward() \n",
    "        optimizer.step() \n",
    "        epoch_loss.append(batch_loss.item()) \n",
    "    \n",
    "    return np.mean(epoch_loss), correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314c88f6",
   "metadata": {},
   "source": [
    "### 4.4.3 The Validation Function\n",
    "The function `evaluate` evaluates the model on specified data. It takes a model and a dataloader and returns the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812bd15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for img, lbl in dataloader:\n",
    "        out = model(img)\n",
    "        logits, indices = torch.max(out, 1)\n",
    "        correct += torch.sum(indices == lbl).item()\n",
    "        total += len(lbl)\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14ab5d0",
   "metadata": {},
   "source": [
    "### Task 4.4.4 The Training Loop\n",
    "Write the training loop for your model:\n",
    "- Call the `train` function for your model for the specified number of epochs. \n",
    "- For each epoch, keep track of the loss and the training accuracy.\n",
    "- You should also keep track of the validation accuracy, to judge the models actual performance on unseen data.\n",
    "- Store all values for visualization purposes later on.\n",
    "\n",
    "Run your training loop! Depending on the size of your network architecture and the number of epochs, this might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f107c25e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd62da",
   "metadata": {},
   "source": [
    "### Task 4.4.5 Visualize the Training\n",
    "Visually inspecting the models behavior over the training period can give insights on problems and performance issues.\n",
    "\n",
    "Plot (A) the training loss and the training accuracy and (B) the validation accuracy over the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee9bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79b29eb",
   "metadata": {},
   "source": [
    "## 4.5 Testing your Model\n",
    "The following should only be executed once. If you are not satisfied with your model performance, go back a few steps and tune your model with different parameters or change the model architecture.\n",
    "\n",
    "If you are checking your model's performance on the test set and then tune it for better performance, you are essentially fitting your model to the test set. Your actual generalization capabilities will decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e544354",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = evaluate(model, testloader)\n",
    "print(\"Your model correctly classified\", round(test_acc*100,2), \n",
    "      \"% of all samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6fe32a",
   "metadata": {},
   "source": [
    "### Task 4.5.1 Prediction Capabilities of the Model\n",
    "Although we now know the average prediction performance of the model on unseen data, not all data is as equally distributed as our training data. Some classes can be harder to predict than others.\n",
    "\n",
    "Analyze your models performance on the different classes and plot the prediction accuracies on the test set over the 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08533094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe942e8",
   "metadata": {},
   "source": [
    "## 4.6 Convolutional Neural Networks (CNN) (Bonus)\n",
    "If you want to build more sophisticated models to process images, CNNs are the specialized kind of neural network for processing data that has a known, grid-like topology. \n",
    "\n",
    "In what follows, you will get more familiar with this concept. In the __theoretical section__ we make you intuitively comfortable with the terms. Further in the __practical section__, you have to implement your own CNN like architecture (of course building/finetune youre CNNs around more sophisticated models like [ResNet](https://pytorch.org/vision/stable/models.html#id10) architectures is also possible). After you builded youre architecture, the task is to do the same steps like in the previous tasks (you can use youre already implemented functions!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c026aeca",
   "metadata": {},
   "source": [
    "### 4.6.1 Theoretical Section\n",
    "\n",
    "### Convolution layer\n",
    "The name \"convolutional neural network\" indicates that the network uses a mathematical operation called convolution. Convolutional neural networks are simply neural networks that use convolution instead of general matrix multiplication in at least one of their layers. It expresses the amount of overlap of one function when it's shifted over another function. You can think of your eyes crossing over objects. Let's see it in action: \n",
    "\n",
    "![Alt Text](https://upload.wikimedia.org/wikipedia/commons/6/6a/Convolution_of_box_signal_with_itself2.gif)\n",
    "\n",
    "<img src=\"https://render.githubusercontent.com/render/math?math=\\displaystyle (f*g)(n)=\\sum _{m=-\\infty }^{\\infty }f(m)g(n-m)\">\n",
    "\n",
    "As you can see in the above picture from left to right, we slide with the function $g$ against function $f$. In machine learning terms, the function $f$ would be a two-dimensional image and $g$ would be the kernel. In a CNN the opertion would look like this and is called a convolution layer:\n",
    "\n",
    "<img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/convolution-layer-a.png?1c517e00cb8d709baf32fc3d39ebae67\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "The convolution layer uses filters/kernels that perform convolution operations as it is scanning the 2D image $I$. The hyperparameters include the filter size $F$ and stride $S$. The resulting output $O$ is called feature map/activation map. In the animation above you can see on the left the input image $I$, which gets scanned by the filter $F$ with a stride $S$ = 1. If you want, you can play interactively with [ConvPlayer](https://setosa.io/ev/image-kernels/) to get a more intuitive understanding about kernels/filters.\n",
    "\n",
    "### Pooling layer \n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/6d0f5eac1c020be6f540df82378de7cc1570c1ba500b7e83ee6377e10a508ecc/68747470733a2f2f6d6c6e6f7465626f6f6b2e6769746875622e696f2f696d672f434e4e2f706f6f6c6669672e676966\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "\n",
    "The above animation shows max pooling, average pooling only takes the average value in the receptive (scanning) field. The pooling layer is a downsampling operation applied after a convolution layer. Particular, max and average pooling are special kinds of pooling where the maximum and average value is taken. \n",
    "\n",
    "### Fully Connected\n",
    "\n",
    "<img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/fully-connected-ltr.png?32caf9e07c79d652faa292812579d063=50x20\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "Fully connected layer operates on a flattened input where each input is connected to all neurons. Fully connected layers are usually found towards the end of CNN architectures.\n",
    "\n",
    "### Overview\n",
    "<img src=\"https://miro.medium.com/max/1400/1*vkQ0hXDaQv57sALXAJquxA.jpeg\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "Putting it all together you get an CNN. A filter of size $F \\times F$ applied to an input containing $C$ channels is a $F \\times F \\times C$ volume that performs convolutions on an input of size $I \\times I \\times C$ and produces an output feature map of $O \\times O \\times 1$. If you have $K$ filter/kernels of size $F \\times F$ and apply the convolutional operation on input $I \\times I \\times C$ you will get feature map of $O \\times O \\times K$. This is the reason of the volumes in the above picture.\n",
    "\n",
    "For a CNN to learn, it uses the same backpropagation algorithm. Although it may seem a little bit complicated how to do [gradient descent](https://de.wikipedia.org/wiki/Gradientenverfahren) on a CNN, it's really simple if you go through the operations step by step. If you want to have a more in-depth knowledge of how to train - from a mathematical viewpoint - a CNN, we recommend you to read this great [blogpost](https://pavisj.medium.com/convolutions-and-backpropagations-46026a8f5d2c). The really short explanation is $F_{new} = F_{old} - µ \\frac{∂L}{∂F_{old}}$, so we update our filters/kernels based on the difference of the old filters $F_{old}$ and the derivate of the loss $L$ with respect to $F_{old}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2789a3",
   "metadata": {},
   "source": [
    "### 4.6.2 Practical Section\n",
    "\n",
    "In this section you have to implement your own CNN architecture. Please use the same dataset and do the same like in the previous tasks 4.3 to 4.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75db5a3",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "You can use this template to build your CNN or use another if you want. If you use a class to build your model, don't forget to first instantiate your model object after you have built it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d64a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as act\n",
    "\n",
    "class NN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "         # your code here (network layers)\n",
    "        self.a1 = nn.Conv2d(3, 96, kernel_size=2)\n",
    "        self.fc1 = nn.Linear(96 * 2 * 2, 432)\n",
    "        self.fc2 = nn.Linear(432, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # your code here\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b761ce",
   "metadata": {},
   "source": [
    "### Train Loop\n",
    "Here use your already implemented functions to train your model.\n",
    "\n",
    "_Hint: copy and paste! ;)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20027f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b70ee",
   "metadata": {},
   "source": [
    "### Visualize the training\n",
    "Again, after you trained your model, plot (A) the training loss and the training accuracy and (B) the validation accuracy over the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309cb6ab",
   "metadata": {},
   "source": [
    "### Testing your Model\n",
    "Now do the same steps like in task 4.5 for testing your CNN. If you want to see the performance of the CNN against the MLP, you can plot the training loss and the training accuracy on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
