{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55f9b6dc",
   "metadata": {
    "id": "55f9b6dc"
   },
   "source": [
    "# 3 Custom Environments\n",
    "In this task you are asked to create a environment for a reinforcement agent. It's common to create environments for agents by using the openai gym interface. It creates a good baseline for what is necessary to train a RL agent and makes it easy to try out different environments on the same algorithm.\n",
    "If you need more information take a look at the documentation https://www.gymlibrary.ml/.\n",
    "You can find the implementation of all official enviroments on GitHub: https://github.com/openai/gym/tree/master/gym/envs if you need some examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46e9eed",
   "metadata": {
    "id": "d46e9eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym==0.21.0 in c:\\users\\jakob\\.julia\\conda\\3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\jakob\\.julia\\conda\\3\\lib\\site-packages (from gym==0.21.0) (1.22.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jakob\\.julia\\conda\\3\\lib\\site-packages (from gym==0.21.0) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gym==0.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e12a89a",
   "metadata": {
    "id": "1e12a89a"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a7d886",
   "metadata": {
    "id": "e4a7d886"
   },
   "source": [
    "## 3.1 The Environment\n",
    "A openai gym environment consists of at least 3 methods. `__init__` the constructor which sets all the necassary values, a `step` function, which describes the behaviour of the environment and a `reset` function, which resets the starting state of the environment. In addition to that usually a `render` function is provided to visualize the behaviour of the environment.\n",
    "\n",
    "#### \\__init__:\n",
    "The Constructor of the environment defines all the necassary variables. To set the bounds of our environment we have to define the action_space and the observartion space. The gym.spaces library contains the necassary functions to do in our case we use gym.spaces.Discrete because we wan to only handle discrete values.\n",
    "The Discrete space works a bit like a range, with some extra methods. A Linear representation of the state is helpful for tabular learning, because it makes creating a Q-Table really easy. \n",
    "\n",
    "#### step:\n",
    "The step method takes an action and returns a tuple of the shape(observation, reward, done). The observation is the result of taking the action. The reward is the reward handet for takin given action in the previous state. The done variable is boolean and indicates if a given scenario has come to an end. \n",
    "\n",
    "#### reset:\n",
    "The reset method rests the start state of the environment. It returns the new state of the environment.\n",
    "\n",
    "#### render:\n",
    "The render method visualizes the state of the environment. There are many different ways to do so i.e. creating a visual representation by using vector graphics or printing to the terminal. \n",
    "We want to focus on the easiest way, by printing the state. Find a good and easily printable representation of the internal state (i.e. a numpy array) and print it. To print over the last output you can call the  function before you print the state.\n",
    "\n",
    "### Encoding and decoding\n",
    "This functions are not necessary for a gym environment. However it might be usefull do write some functions that encode and decode the linearized state to a 2D imensional Form and back.\n",
    "\n",
    "#### decode_action\n",
    "returns the action refering to the index of the action\n",
    "\n",
    "#### decode_state\n",
    "returns a 2D representation of the linear state\n",
    "\n",
    "#### encode_state\n",
    "returns a linear representation of the 2D state.\n",
    "\n",
    "\n",
    "### Task 3.1.1\n",
    "- Create a two dimensional, discrete environment of the size 10x10.\n",
    "- Each episode the agent should start at a random position, while the target always stays at the same position.\n",
    "- The agent should be able to move in all 4 directions, If the agent hits a wall it should do nothing.\n",
    "- An episode ends if the agent reaches the target.\n",
    "- Reaching the target results in a reward of 10, while every other action should give a small negative reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "174d6193",
   "metadata": {
    "id": "174d6193"
   },
   "outputs": [],
   "source": [
    "class CustomEnv(gym.Env):\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CustomEnv, self).__init__()\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "\n",
    "        self.observation_space = gym.spaces.Discrete(10 * 10)\n",
    "\n",
    "        self.agent_state = np.random.randint(0, 9, 2)\n",
    "        self.original_agent_state = self.agent_state\n",
    "        self.target_state = [2, 2]\n",
    "\n",
    "    def step(self, action):\n",
    "        # Write the step method for your enviroment. Make sure you agent does not go out of bounds\n",
    "        # by performing the action.\n",
    "        assert self.action_space.contains(action), \"%r (%s) invalid\" % (\n",
    "            action,\n",
    "            type(action),\n",
    "        )\n",
    "        self.agent_state += self.decode_action(action)\n",
    "\n",
    "        if self.agent_state[0] < 0:\n",
    "            self.agent_state[0] = 0\n",
    "        elif self.agent_state[0] > 9:\n",
    "            self.agent_state[0] = 9\n",
    "        if self.agent_state[1] < 0:\n",
    "            self.agent_state[1] = 0\n",
    "        elif self.agent_state[1] > 9:\n",
    "            self.agent_state[1] = 9\n",
    "\n",
    "        reward = -1\n",
    "        done = False\n",
    "        # check for ending condition\n",
    "        if np.array_equal(self.agent_state, self.target_state):\n",
    "            reward = 10\n",
    "            done = True\n",
    "\n",
    "        return (self.encode_state(self.agent_state), reward, done, _)\n",
    "\n",
    "    def reset(self):\n",
    "        # Write the reset method that results in the starting state\n",
    "        self.agent_state = self.original_agent_state\n",
    "        return self.encode_state(self.agent_state)\n",
    "\n",
    "    def render(self):\n",
    "        print(\" \" + \"_\" * 10 * 3 + \" \")\n",
    "\n",
    "        for i in range(10):\n",
    "            print(\"|\", end=\"\")\n",
    "            for j in range(10):\n",
    "                print(\" \", end=\"\")\n",
    "                if np.array_equal([i, j], self.agent_state):\n",
    "                    print(\"A\", end=\"\")\n",
    "                elif np.array_equal([i, j], self.target_state):\n",
    "                    print(\"T\", end=\"\")\n",
    "                else:\n",
    "                    print(\"_\", end=\"\")\n",
    "                print(\" \", end=\"\")\n",
    "            print(\"|\")\n",
    "\n",
    "    def decode_action(self, action):\n",
    "        # decode a linear action to 2D\n",
    "        return [[-1, 0], [0, 1], [1, 0], [0, -1]][action]\n",
    "\n",
    "    def decode_state(self, state):\n",
    "        # decode a linear state to 2D\n",
    "        return [state // 10, state % 10]\n",
    "\n",
    "    def encode_state(self, state):\n",
    "        # encode a 2D state in 1D\n",
    "        assert len(state) == 2\n",
    "        coord = state[0] + state[1] * 10\n",
    "        assert coord >= 0 and coord < 100, \"Invalid state: %s\" % state\n",
    "        return coord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebcdafe",
   "metadata": {
    "id": "3ebcdafe"
   },
   "source": [
    "## 3.2 Test with a random agent\n",
    "The following cell allows you to test your enviroment with a random agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3dc404a",
   "metadata": {
    "id": "a3dc404a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ______________________________ \n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  T  _  A  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n"
     ]
    }
   ],
   "source": [
    "env = CustomEnv()\n",
    "done = False\n",
    "i = 50  # added a manual stop so this doesnt run into eternity everytime\n",
    "\n",
    "while done == False and i > 0:\n",
    "    a = env.action_space.sample()\n",
    "    _, _, done, _ = env.step(a)\n",
    "    clear_output(wait=True)\n",
    "    env.render()\n",
    "    time.sleep(0.1)\n",
    "    i -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa73e00f",
   "metadata": {
    "id": "aa73e00f"
   },
   "source": [
    "## Task 3.3 Test with a Q-Learning Agent\n",
    "In the previous task we wrote an agent that used the SARSA algorithm. Now we want to use a similar algorithm, Q-Learning, to solve your own custom environment. And of course visualise your training progress (Cumulative rewards over time).\n",
    "\n",
    "The main difference between SARSA and Q-Learning is the way the Q-Values are calculated. Therefore, you can recycle most of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a34d4e1",
   "metadata": {
    "id": "3a34d4e1"
   },
   "outputs": [],
   "source": [
    "def evaluate(policy):\n",
    "    # evaluate a policy by running 20 independent episodes\n",
    "    scores = []\n",
    "    for i in range(20):\n",
    "        obs = env.reset()\n",
    "        score = 0\n",
    "        while True:\n",
    "            action = policy(obs)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            if done:\n",
    "                break\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bb60cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ceaae15b20>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epsilon = 0.1\n",
    "gamma = 0.99\n",
    "learning_rate = 0.2\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "episodes = 40000\n",
    "\n",
    "\n",
    "def eps_greedy(state):\n",
    "    if np.random.random() < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        return np.argmax(Q[state])\n",
    "\n",
    "\n",
    "def update_table(s, a, delta):\n",
    "    Q[s, a] += learning_rate * delta\n",
    "\n",
    "\n",
    "def train():\n",
    "    scores = []\n",
    "    for _ in range(episodes):\n",
    "        s = env.reset()\n",
    "        score = 0\n",
    "\n",
    "        while True:\n",
    "            a = eps_greedy(s)\n",
    "            next_s, r, done, _ = env.step(a)\n",
    "\n",
    "            old_value = Q[s, a]\n",
    "            next_max = np.max(Q[next_s])\n",
    "\n",
    "            Q[s, a] = (1 - learning_rate) * old_value + learning_rate * (\n",
    "                r + gamma * next_max\n",
    "            )\n",
    "            s = next_s\n",
    "            score += r\n",
    "            if done:\n",
    "                break\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "\n",
    "results = train()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Training Results (Q-learning)\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22b5526c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ______________________________ \n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  T  _  _  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  A  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n",
      "| _  _  _  _  _  _  _  _  _  _ |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4544/3333606669.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = CustomEnv()\n",
    "done = False\n",
    "s = env.reset()\n",
    "while done == False:\n",
    "\n",
    "    a = np.argmax(Q[s])\n",
    "    s, _, done, _ = env.step(a)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    env.render()\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea757dd",
   "metadata": {
    "id": "8ea757dd"
   },
   "source": [
    "### Task 3.3.1 Size concerns for Tabular RL:\n",
    "The table for learning our simple enviroment has the size 100x4 for now. Since we have 100 possible States and 4 actions. How much bigger would the table get if we allowed the target to be placed anywhere?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a53e6db",
   "metadata": {
    "id": "4a53e6db"
   },
   "outputs": [],
   "source": [
    "# Right now we have 100 different states, since the agent can be  anywhere on\n",
    "# the 10x10 grid, but the target location is static\n",
    "# (so not part of the dynamic state). If we allowed for the target to be placed\n",
    "# randomly, so in one of 100 different locations, we would have 100 x 100\n",
    "# different possible states. So our Matrix would grow to a 10000x4 big matrix.\n",
    "# If we assume the matrix is using a double precission float, the matrix would\n",
    "# use 320 kB of memory (prior 3.2kB)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CustomEnvironment.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "2a2892602ff1729df00a2fd3e807d6b422d83bb53afb12387f9daea05a7313bf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
